""" 
RSV-A Sequencing Analysis Pipeline.
Author: Will Hannon 
"""

#### ----------------------- Imports ----------------------- ####

import pandas as pd 
from os.path import join

#### -------------------- Configuration -------------------- ####

configfile: "configuration/pipeline.yml"

#### ----------------------- Targets ----------------------- ####

sample_df = pd.read_csv(config['samples'])

rule all:
    input:
        expand(join(config['variants_dir'], "{sample}.tsv"), sample=sample_df['Run'].unique()),
        join(config['coverage_dir'], "merged.depth")

#### ------------------------ Rules ------------------------ ####

rule clean:
    shell:
        """
        rm -rf logs/
        rm -rf tmp/
        rm -f slurm*.out
        """


rule get_gff:
    """ 
    Download the gff format gene annotation.
    """
    output: join(config['reference_dir'], 'RSVA.gff')
    params: ftp = lambda wildcards: config['gff']
    shell: 
        """
        wget -O - {params.ftp} | gunzip -c > {output}
        """
    

rule get_ref:
    """ 
    Download the fasta format reference genome.
    """
    output: join(config['reference_dir'], 'RSVA.fasta')
    params: ftp = lambda wildcards: config['ref']
    shell: 
        """
        wget -O - {params.ftp} | gunzip -c > {output}
        """


rule bwa_index:
    """ 
    Index the genome with BWA before alignment with BWA. 
    """
    input: join(config['reference_dir'], 'RSVA.fasta')
    output: join(config['reference_dir'], "bwa", 'RSVA.fasta')
    conda: 'envs/align-reads.yml'
    params: algorithm="bwtsw"
    shell:
        """
        cp {input} {output}
        bwa index -a {params.algorithm} {output}
        """


rule fetch_fastq_files:
    """ 
    Move the fastq files into the results directory and rename the files. 
    """
    output: R1 = join(config['fastq_dir'], "{sample}", "{sample}_R1.fastq.gz"),
            R2 = join(config['fastq_dir'], "{sample}", "{sample}_R2.fastq.gz")
    params: R1_path = lambda wildcards: sample_df.loc[(sample_df.Run == wildcards.sample)].R1.item(),
            R2_path = lambda wildcards: sample_df.loc[(sample_df.Run == wildcards.sample)].R2.item()
    shell: "cp {params.R1_path} {output.R1} && cp {params.R2_path} {output.R2}"


rule trim_adapters_sequences_with_fastp:
    """
    Use fastp to trim the adapters from the reads.

    1. Automatic adaptor trimming
    2. Low-qual base filtering (40% of bases w/ Phred >15) 
    3. Reporting by HTML and JSON.
    """
    input:  
        R1 = join(config['fastq_dir'], "{sample}", "{sample}_R1.fastq.gz"),
        R2 = join(config['fastq_dir'], "{sample}", "{sample}_R2.fastq.gz")
    output:
        R1 = join(config['trim_dir'], "{sample}", "{sample}_R1.fastq.gz"),
        R2 = join(config['trim_dir'], "{sample}", "{sample}_R2.fastq.gz"),
        html = join(config['qc_dir'], "{sample}", "{sample}.fastp.html"),
        json = join(config['qc_dir'], "{sample}", "{sample}.fastp.json")
    conda: 'envs/process-reads.yml'
    shell:
        """ 
        fastp \
            -i {input.R1} \
            -I {input.R2} \
            -o {output.R1} \
            -O {output.R2} \
            --html {output.html} \
            --json {output.json} 
        """
        

rule align_stock_with_bwa:
    """ 
    Perform short read alignment of the stock
    viral reads with bwa-mem.
    
    Sort the aligned reads with samtools sort.
    """
    input: 
        R1 = join(config['trim_dir'], "{sample}", "{sample}_R1.fastq.gz"),
        R2 = join(config['trim_dir'], "{sample}", "{sample}_R2.fastq.gz"),
        genome = join(config['reference_dir'], "bwa", 'RSVA.fasta')
    output: bam = join(config['consensus_dir'], "{sample}.sorted.bam"),
            bai = join(config['consensus_dir'], "{sample}.sorted.bam.bai")
    threads: config['threads']['max_cpu']
    conda: 'envs/align-reads.yml'
    shell: 
        """
        bwa mem -t {threads} \
            {input.genome} \
            {input.R1} {input.R2} | \
            samtools view -bh | \
            samtools sort -o {output.bam} - 
        samtools index {output.bam}
        """


rule create_stock_consensus_with_ivar:
    input: bam = join(config['consensus_dir'], "{sample}.sorted.bam")
    output: join(config['consensus_dir'], "{sample}.fa")
    params: prefix = join(config['consensus_dir'], "{sample}")
    conda: 'envs/call-variants.yml'
    shell:
        """
        samtools mpileup -d 1000 -A -Q 0 {input.bam} | ivar consensus -p {params.prefix} -q 20 -t 0
        """


rule index_stock_consensus_with_bwa:
    """ 
    Index the stock consensus genome with BWA before alignment with BWA. 
    """
    input: join(config['consensus_dir'], "{sample}.fa")
    output: join(config['reference_dir'], "bwa", "{sample}.fa")
    conda: 'envs/align-reads.yml'
    params: algorithm="bwtsw"
    shell:
        """
        cp {input} {output}
        bwa index -a {params.algorithm} {output}
        """


rule align_all_reads_with_bwa:
    """ 
    Perform short read alignment of the 
    viral reads with bwa-mem.
    
    Sort the aligned reads with samtools sort.
    """
    input: 
        R1 = join(config['trim_dir'], "{sample}", "{sample}_R1.fastq.gz"),
        R2 = join(config['trim_dir'], "{sample}", "{sample}_R2.fastq.gz"),
        genome = join(config['reference_dir'], "bwa", "Stock.fa")
    output: bam = join(config['align_dir'], "{sample}.sorted.bam"),
            bai = join(config['align_dir'], "{sample}.sorted.bam.bai")
    threads: config['threads']['max_cpu']
    conda: 'envs/align-reads.yml'
    shell: 
        """
        bwa mem -t {threads} \
            {input.genome} \
            {input.R1} {input.R2} | \
            samtools view -bh | \
            samtools sort -o {output.bam} - 
        samtools index {output.bam}
        """


rule call_variants_with_ivar:
    input: 
        bam = join(config['align_dir'], "{sample}.sorted.bam"),
        genome = join(config['reference_dir'], "bwa", "Stock.fa"),
        gff = join(config['reference_dir'], 'RSVA.gff')
    output: join(config['variants_dir'], "{sample}.tsv")
    params: prefix = join(config['variants_dir'], "{sample}")
    conda: 'envs/call-variants.yml'
    shell:
        """
        samtools mpileup -aa -A -d 1000 -B -Q 0 {input.bam} | ivar variants -p {params.prefix} -q 20 -t 0.02 -r {input.genome} -g {input.gff}
        """


rule samtools_depth:
    """ 
    Calculate the depth over each position filtering by the phred base score. 
    """
    input: bam = join(config['align_dir'], "{sample}.sorted.bam")
    output: join(config['coverage_dir'], "{sample}.depth")
    params: score=25
    conda: 'envs/align-reads.yml'
    shell: 
        """
        samtools depth -a -d 0 -q {params.score} {input.bam} > {output}

        sed -i "s/$/\t{wildcards.sample}/" {output} 
        """


rule merge_depth:
    """ 
    Merge the samtools depth tables for all of the accessions into a single file.
    """
    input: expand(join(config['coverage_dir'], "{sample}.depth"), sample=sample_df['Run'].unique())
    output: depth = join(config['coverage_dir'], "merged.depth"),
            header = temp(join(config['coverage_dir'], "merged.depth.tmp"))
    shell:
        """
        cat {input} > {output.header}

        awk 'BEGIN{{print "REF\tPOS\tDP\tSample"}}1' {output.header} > {output.depth}
        """

